{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative adversarial network\n",
    "\n",
    "Questo notebook è una versione semplificata del codice per la 'vanilla GAN' che trovate qui:\n",
    "https://github.com/wiseodd/generative-models\n",
    "\n",
    "Per eseguirlo è sufficiente installare TensorFlow: \n",
    "https://www.tensorflow.org/install/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo le variabili per il discriminatore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "\n",
    "D_W1 = tf.Variable(tf.random_normal(shape=[784, 128], stddev=0.1))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "D_W2 = tf.Variable(tf.random_normal(shape=[128, 1], stddev=0.1))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo le variabili per il generatore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "\n",
    "G_W1 = tf.Variable(tf.random_normal(shape=[100, 128], stddev=0.1))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "G_W2 = tf.Variable(tf.random_normal(shape=[128, 784], stddev=0.1))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[784]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una funzione per campionare un possibile ingresso al generatore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rete neurale del generatore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "\n",
    "    return G_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rete neurale del discriminatore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    D_prob = tf.nn.sigmoid(D_logit)\n",
    "\n",
    "    return D_prob, D_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzioni costo individuali e complessive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_sample = generator(Z)\n",
    "D_real, D_logit_real = discriminator(X)\n",
    "D_fake, D_logit_fake = discriminator(G_sample)\n",
    "\n",
    "D_loss = -tf.reduce_mean(tf.log(D_real) + tf.log(1. - D_fake))\n",
    "G_loss = -tf.reduce_mean(tf.log(D_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ottimizzazione (si noti come le due funzioni costo vengono aggiornate in maniera alternata):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../../MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter: 0\n",
      "D loss: 2.329\n",
      "G_loss: 1.205\n",
      "\n",
      "Iter: 1000\n",
      "D loss: 0.01016\n",
      "G_loss: 13.69\n",
      "\n",
      "Iter: 2000\n",
      "D loss: 0.0108\n",
      "G_loss: 7.179\n",
      "\n",
      "Iter: 3000\n",
      "D loss: 0.003816\n",
      "G_loss: 7.975\n",
      "\n",
      "Iter: 4000\n",
      "D loss: 0.01483\n",
      "G_loss: 5.927\n",
      "\n",
      "Iter: 5000\n",
      "D loss: 0.105\n",
      "G_loss: 5.521\n",
      "\n",
      "Iter: 6000\n",
      "D loss: 0.1269\n",
      "G_loss: 4.55\n",
      "\n",
      "Iter: 7000\n",
      "D loss: 0.241\n",
      "G_loss: 4.184\n",
      "\n",
      "Iter: 8000\n",
      "D loss: 0.3828\n",
      "G_loss: 3.445\n",
      "\n",
      "Iter: 9000\n",
      "D loss: 0.4619\n",
      "G_loss: 3.355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G)\n",
    "\n",
    "mb_size = 128\n",
    "Z_dim = 100\n",
    "\n",
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for it in range(10000):\n",
    "    \n",
    "    X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "\n",
    "    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(mb_size, Z_dim)})\n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(mb_size, Z_dim)})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('D loss: {:.4}'. format(D_loss_curr))\n",
    "        print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione per mostrare l'immagine ingrandita:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "    image = PIL.Image.fromarray(a)\n",
    "    display(image.resize((28*5, 28*5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Campioniamo il generatore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = sess.run(G_sample, feed_dict={Z: sample_Z(1, Z_dim)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostriamo l'uscita:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIwAAACMCAAAAACLqx7iAAACr0lEQVR4nO3bP2jdVRTA8U/+iCbG\nitaodasSgqWD2bRLuwgOQhehg4J0UJw6uXRwKMVNcBHErVCHDpKt1S4dQhGK4iCliGuWUtKhIOQl\nMY1DLr+W0kvevalwxPOd3u/d9w5fDucd7u/c3yNJkiRJkiRJkiT5zzCxry/uwDS8D1eG9/6GqeHV\nmEz2yvwbpEyNUDI9BTwH63AMvobn4S58ALdhGw7C2niBQ2UmZWqEkplu+vSu+ohSu9fgF3gFrsPb\ncGh474vm8EFImRqhZHo68DS8CZfhBUpRr8EB+Aa+hQ1Ku96bUJlJmRqhZNo68C7b8BG8BM9QCngE\nd+AMnIK3GgKHykzK1EiZGj2/ppdhAX6Fd2AGVmATDsPx1sChMpMyNULJ9GzIX4clyo3jKlyA03CV\nUs9j7mIeDR+ElKkRSqatgJ8Gr8Il+ASeovTiN+ArWB4Wtihzvr0JlZmUqRFKpu2OcgrMUkYiq3Ae\nnoPPh4Wf4TX4qSF8qMykTI1QMm0FPAf+omwS3oMX4SicpJTtWbjI2PNoBMtMytQIJdNWwLvq94fr\nefgB3qU05PlhdZlyyNIUPggpUyOUTNse+P4j1yM4QdlWjIaFHfixVSZUZlKmRiiZnjHaA5Yow7N1\nymZiC+7BzdZwoTKTMjVCyeyvgFeGVxPwLOXMZQ0W4UZDuFCZSZkaoWS6H417wCRlgvYbpfluU846\nNlsjRSFlaoSS6e7AEzx8pD1LmUzMUoZnLbWLYJlJmRqhZLoLeIcyF/4MPuXhB5b/6IoZKjMpUyOU\nTE8BT8LH8B18CEeG1XPwZZdMqMykTI1QMt0FfIvSgb8fFi7Bn4x9dvy4wFFImRqhZLofTl6g/Hlp\nEX6nHGT01S6CZSZlaoSS6Z5CzFAONjaelEuszKRMjVAySZIk/yv+AQYUWYsdiJx0AAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=140x140 at 0x130E4A20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showarray(sample.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
